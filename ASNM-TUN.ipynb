{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Classification Baselines for Anomaly-based Network Intrusion Detection Systems "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "np.random.seed(7)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ASNM-datasets/ASNM-TUN.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing missing spaces with mean of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using attributes from Feature Selection for our input data and make out output data label 3\n",
    "### Label 3: distinguishes among legitimate traffic (symbol 3), direct and obfuscated network attacks (symbols 1 and 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFSCols = ['PolyInd10ordOut[3]',\n",
    " 'OutPktLen64s10i[8]',\n",
    " 'OutPkt4s10i[7]',\n",
    " 'ConTcpFinCntIn',\n",
    " 'GaussProds4In[1]',\n",
    " 'FourGonAngleAllN[2]',\n",
    " 'MedTCPHdrLen',\n",
    " 'GaussProds8In[5]',\n",
    " 'SumTTLOut',\n",
    " 'PolyTime10ordOut[2]',\n",
    " 'InPkt64s20iTr2KB[14]',\n",
    " 'OutPktLen64s10i[5]',\n",
    " 'PolyInd13ordIn[7]',\n",
    " 'InPkt1s10i[8]',\n",
    " 'OutPkt32s20iTr4KB[11]',\n",
    " 'PolyTime10ordOut[8]',\n",
    " 'OutPktLen4s10i[3]',\n",
    " 'PolyInd13ordOut[13]',\n",
    " 'PolyInd13ordIn[12]',\n",
    " 'InPkt64s20iTr2KB[7]']\n",
    "X = df[FFSCols].values\n",
    "y = df[['label_3']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0.1,0.9))\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the output for multiclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Neural Network baseline model with Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/ajay340/asnm-tun\" target=\"_blank\">https://app.wandb.ai/ajay340/asnm-tun</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/ajay340/asnm-tun/runs/iwv80n8p\" target=\"_blank\">https://app.wandb.ai/ajay340/asnm-tun/runs/iwv80n8p</a><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "---------------------------\naccuracy: 87.34%\n---------------------------\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/ajay340/asnm-tun\" target=\"_blank\">https://app.wandb.ai/ajay340/asnm-tun</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/ajay340/asnm-tun/runs/1y2aykw1\" target=\"_blank\">https://app.wandb.ai/ajay340/asnm-tun/runs/1y2aykw1</a><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "---------------------------\naccuracy: 78.48%\n---------------------------\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/ajay340/asnm-tun\" target=\"_blank\">https://app.wandb.ai/ajay340/asnm-tun</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/ajay340/asnm-tun/runs/3dnhgark\" target=\"_blank\">https://app.wandb.ai/ajay340/asnm-tun/runs/3dnhgark</a><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "---------------------------\naccuracy: 70.89%\n---------------------------\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/ajay340/asnm-tun\" target=\"_blank\">https://app.wandb.ai/ajay340/asnm-tun</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/ajay340/asnm-tun/runs/34ea5gol\" target=\"_blank\">https://app.wandb.ai/ajay340/asnm-tun/runs/34ea5gol</a><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "---------------------------\naccuracy: 87.34%\n---------------------------\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/ajay340/asnm-tun\" target=\"_blank\">https://app.wandb.ai/ajay340/asnm-tun</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/ajay340/asnm-tun/runs/skzj2re5\" target=\"_blank\">https://app.wandb.ai/ajay340/asnm-tun/runs/skzj2re5</a><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "---------------------------\naccuracy: 84.62%\n---------------------------\n81.73% (+/- 6.32%)\n"
    }
   ],
   "source": [
    "cvscores = []\n",
    "for train, test in kfold.split(X, y):\n",
    "        wandb.init(project=\"asnm-tun\")\n",
    "        model = Sequential()\n",
    "        model.add(Dense(X.shape[1]+1, input_dim=X.shape[1], activation='relu'))\n",
    "        model.add(Dense(40,activation='relu'))\n",
    "        model.add(Dense(60,activation='relu'))\n",
    "        model.add(Dense(30,activation='relu'))\n",
    "        model.add(Dense(10,activation='relu'))\n",
    "        model.add(Dense(y.shape[1], activation='softmax'))\n",
    "        opt = keras.optimizers.Adam(learning_rate=0.009)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(\n",
    "                X[train],\n",
    "                y[train],\n",
    "                epochs=1200,\n",
    "                verbose=0,\n",
    "                batch_size=10,\n",
    "                callbacks=[WandbCallback()]\n",
    "        )\n",
    "        model.save(\"model.h5\")\n",
    "        open(\"model.json\", \"w\").write(model.to_json())\n",
    "        scores = model.evaluate(X[test], y[test], verbose=0)\n",
    "        cvscores.append(scores[1] * 100)\n",
    "        wandb.save('model.h5')\n",
    "        wandb.save('model.json')\n",
    "        \n",
    "        print(\"---------------------------\")\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        print(\"---------------------------\")\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Neural Network baseline model with SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/ajay340/asnm-tun\" target=\"_blank\">https://app.wandb.ai/ajay340/asnm-tun</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/ajay340/asnm-tun/runs/3ate0mgo\" target=\"_blank\">https://app.wandb.ai/ajay340/asnm-tun/runs/3ate0mgo</a><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "---------------------------\naccuracy: 75.95%\n---------------------------\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/ajay340/asnm-tun\" target=\"_blank\">https://app.wandb.ai/ajay340/asnm-tun</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/ajay340/asnm-tun/runs/rcxrtcz9\" target=\"_blank\">https://app.wandb.ai/ajay340/asnm-tun/runs/rcxrtcz9</a><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "---------------------------\naccuracy: 65.82%\n---------------------------\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/ajay340/asnm-tun\" target=\"_blank\">https://app.wandb.ai/ajay340/asnm-tun</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/ajay340/asnm-tun/runs/1u3uadmc\" target=\"_blank\">https://app.wandb.ai/ajay340/asnm-tun/runs/1u3uadmc</a><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "---------------------------\naccuracy: 60.76%\n---------------------------\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/ajay340/asnm-tun\" target=\"_blank\">https://app.wandb.ai/ajay340/asnm-tun</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/ajay340/asnm-tun/runs/1mvh64p0\" target=\"_blank\">https://app.wandb.ai/ajay340/asnm-tun/runs/1mvh64p0</a><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "---------------------------\naccuracy: 63.29%\n---------------------------\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/ajay340/asnm-tun\" target=\"_blank\">https://app.wandb.ai/ajay340/asnm-tun</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/ajay340/asnm-tun/runs/1bgah9yv\" target=\"_blank\">https://app.wandb.ai/ajay340/asnm-tun/runs/1bgah9yv</a><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "---------------------------\naccuracy: 76.92%\n---------------------------\n68.55% (+/- 6.64%)\n"
    }
   ],
   "source": [
    "cvscores = []\n",
    "for train, test in kfold.split(X, y):\n",
    "        wandb.init(project=\"asnm-tun\")\n",
    "        model = Sequential()\n",
    "        model.add(Dense(X.shape[1]+1, input_dim=X.shape[1], activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(40,activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(60,activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(30,activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(10,activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(y.shape[1], activation='softmax'))\n",
    "        opt = SGD(lr=0.01, momentum=0.75)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "        model.fit(\n",
    "                X[train],\n",
    "                y[train],\n",
    "                epochs=1000,\n",
    "                verbose=0,\n",
    "                batch_size=10,\n",
    "                callbacks=[WandbCallback()]\n",
    "        )\n",
    "        model.save(os.path.join(wandb.run.dir, \"model.h5\")) \n",
    "        open(wandb.run.dir + \"/model.json\", \"w\").write(model.to_json())\n",
    "        scores = model.evaluate(X[test], y[test], verbose=0)\n",
    "        cvscores.append(scores[1] * 100)\n",
    "\n",
    "        print(\"---------------------------\")\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        print(\"---------------------------\")\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building baseline model with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n   Legitmate       0.97      1.00      0.98        30\n      Direct       0.76      0.93      0.84        14\n   Ofuscated       1.00      0.89      0.94        35\n\n   micro avg       0.94      0.94      0.94        79\n   macro avg       0.91      0.94      0.92        79\nweighted avg       0.95      0.94      0.94        79\n samples avg       0.94      0.94      0.94        79\n\n---------------------------\naccuracy: 93.67%\n---------------------------\n              precision    recall  f1-score   support\n\n   Legitmate       0.91      0.87      0.89        23\n      Direct       0.75      0.75      0.75        20\n   Ofuscated       0.86      0.89      0.88        36\n\n   micro avg       0.85      0.85      0.85        79\n   macro avg       0.84      0.84      0.84        79\nweighted avg       0.85      0.85      0.85        79\n samples avg       0.85      0.85      0.85        79\n\n---------------------------\naccuracy: 84.81%\n---------------------------\n              precision    recall  f1-score   support\n\n   Legitmate       0.95      0.95      0.95        21\n      Direct       0.72      0.72      0.72        18\n   Ofuscated       0.85      0.85      0.85        40\n\n   micro avg       0.85      0.85      0.85        79\n   macro avg       0.84      0.84      0.84        79\nweighted avg       0.85      0.85      0.85        79\n samples avg       0.85      0.85      0.85        79\n\n---------------------------\naccuracy: 84.81%\n---------------------------\n              precision    recall  f1-score   support\n\n   Legitmate       0.96      0.92      0.94        26\n      Direct       0.86      0.86      0.86        22\n   Ofuscated       0.88      0.90      0.89        31\n\n   micro avg       0.90      0.90      0.90        79\n   macro avg       0.90      0.90      0.90        79\nweighted avg       0.90      0.90      0.90        79\n samples avg       0.90      0.90      0.90        79\n\n---------------------------\naccuracy: 89.87%\n---------------------------\n              precision    recall  f1-score   support\n\n   Legitmate       0.88      0.93      0.90        30\n      Direct       0.67      0.46      0.55        13\n   Ofuscated       0.89      0.94      0.92        35\n\n   micro avg       0.86      0.86      0.86        78\n   macro avg       0.81      0.78      0.79        78\nweighted avg       0.85      0.86      0.85        78\n samples avg       0.86      0.86      0.86        78\n\n---------------------------\naccuracy: 85.90%\n---------------------------\n87.81% (+/- 3.47%)\n"
    }
   ],
   "source": [
    "cvscores = []\n",
    "for train, test in kfold.split(X, y):\n",
    "    dtree_model = DecisionTreeClassifier(max_depth = 1000).fit(X[train], y[train]) \n",
    "    scores = dtree_model.score(X[test], y[test])\n",
    "    y_pred = dtree_model.predict(X[test])\n",
    "    print(classification_report(y[test], y_pred, target_names=['Legitmate', 'Direct', 'Ofuscated']))\n",
    "    cvscores.append(scores * 100)\n",
    "    print(\"---------------------------\")\n",
    "    print(\"accuracy: %.2f%%\" % (scores*100))\n",
    "    print(\"---------------------------\")\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building baseline model with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n   Legitmate       0.91      1.00      0.95        30\n      Direct       0.92      0.79      0.85        14\n   Ofuscated       0.91      0.89      0.90        35\n\n   micro avg       0.91      0.91      0.91        79\n   macro avg       0.91      0.89      0.90        79\nweighted avg       0.91      0.91      0.91        79\n samples avg       0.91      0.91      0.91        79\n\n---------------------------\naccuracy: 91.14%\n---------------------------\n              precision    recall  f1-score   support\n\n   Legitmate       0.79      0.83      0.81        23\n      Direct       0.67      0.60      0.63        20\n   Ofuscated       0.91      0.86      0.89        36\n\n   micro avg       0.82      0.78      0.80        79\n   macro avg       0.79      0.76      0.78        79\nweighted avg       0.81      0.78      0.80        79\n samples avg       0.78      0.78      0.78        79\n\n---------------------------\naccuracy: 78.48%\n---------------------------\n              precision    recall  f1-score   support\n\n   Legitmate       0.74      0.95      0.83        21\n      Direct       0.58      0.61      0.59        18\n   Ofuscated       0.94      0.72      0.82        40\n\n   micro avg       0.78      0.76      0.77        79\n   macro avg       0.75      0.76      0.75        79\nweighted avg       0.80      0.76      0.77        79\n samples avg       0.76      0.76      0.76        79\n\n---------------------------\naccuracy: 75.95%\n---------------------------\n              precision    recall  f1-score   support\n\n   Legitmate       0.74      0.96      0.83        26\n      Direct       0.92      0.50      0.65        22\n   Ofuscated       0.90      0.90      0.90        31\n\n   micro avg       0.83      0.81      0.82        79\n   macro avg       0.85      0.79      0.79        79\nweighted avg       0.85      0.81      0.81        79\n samples avg       0.81      0.81      0.81        79\n\n---------------------------\naccuracy: 81.01%\n---------------------------\n              precision    recall  f1-score   support\n\n   Legitmate       0.85      0.93      0.89        30\n      Direct       0.60      0.46      0.52        13\n   Ofuscated       0.91      0.91      0.91        35\n\n   micro avg       0.85      0.85      0.85        78\n   macro avg       0.79      0.77      0.77        78\nweighted avg       0.84      0.85      0.84        78\n samples avg       0.85      0.85      0.85        78\n\n---------------------------\naccuracy: 84.62%\n---------------------------\n82.24% (+/- 5.29%)\n"
    }
   ],
   "source": [
    "cvscores = []\n",
    "for train, test in kfold.split(X, y):\n",
    "    knn = KNeighborsClassifier(n_neighbors = 3).fit(X[train], y[train]) \n",
    "    scores = knn.score(X[test], y[test])\n",
    "    y_pred = knn.predict(X[test])\n",
    "    print(classification_report(y[test], y_pred, target_names=['Legitmate', 'Direct', 'Ofuscated']))\n",
    "    cvscores.append(scores * 100)\n",
    "    print(\"---------------------------\")\n",
    "    print(\"accuracy: %.2f%%\" % (scores*100))\n",
    "    print(\"---------------------------\")\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model baseline with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n   Legitmate       1.00      1.00      1.00        30\n      Direct       0.92      0.79      0.85        14\n   Ofuscated       1.00      0.91      0.96        35\n\n   micro avg       0.99      0.92      0.95        79\n   macro avg       0.97      0.90      0.93        79\nweighted avg       0.99      0.92      0.95        79\n samples avg       0.92      0.92      0.92        79\n\n---------------------------\naccuracy: 92.41%\n---------------------------\n              precision    recall  f1-score   support\n\n   Legitmate       1.00      0.87      0.93        23\n      Direct       0.89      0.80      0.84        20\n   Ofuscated       0.87      0.92      0.89        36\n\n   micro avg       0.91      0.87      0.89        79\n   macro avg       0.92      0.86      0.89        79\nweighted avg       0.91      0.87      0.89        79\n samples avg       0.87      0.87      0.87        79\n\n---------------------------\naccuracy: 87.34%\n---------------------------\n              precision    recall  f1-score   support\n\n   Legitmate       0.90      0.90      0.90        21\n      Direct       0.71      0.56      0.63        18\n   Ofuscated       0.94      0.85      0.89        40\n\n   micro avg       0.89      0.80      0.84        79\n   macro avg       0.85      0.77      0.81        79\nweighted avg       0.88      0.80      0.84        79\n samples avg       0.80      0.80      0.80        79\n\n---------------------------\naccuracy: 79.75%\n---------------------------\n              precision    recall  f1-score   support\n\n   Legitmate       0.96      0.88      0.92        26\n      Direct       1.00      0.77      0.87        22\n   Ofuscated       0.94      0.97      0.95        31\n\n   micro avg       0.96      0.89      0.92        79\n   macro avg       0.97      0.88      0.91        79\nweighted avg       0.96      0.89      0.92        79\n samples avg       0.89      0.89      0.89        79\n\n---------------------------\naccuracy: 88.61%\n---------------------------\n              precision    recall  f1-score   support\n\n   Legitmate       0.90      0.93      0.92        30\n      Direct       1.00      0.38      0.56        13\n   Ofuscated       0.87      0.97      0.92        35\n\n   micro avg       0.89      0.86      0.88        78\n   macro avg       0.93      0.76      0.80        78\nweighted avg       0.91      0.86      0.86        78\n samples avg       0.86      0.86      0.86        78\n\n---------------------------\naccuracy: 85.90%\n---------------------------\n86.80% (+/- 4.14%)\n"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X, y):\n",
    "    rfc = RandomForestClassifier(max_depth=1000).fit(X[train], y[train])  \n",
    "    scores = rfc.score(X[test], y[test])\n",
    "    y_pred = rfc.predict(X[test])\n",
    "    print(classification_report(y[test], y_pred, target_names=['Legitmate', 'Direct', 'Ofuscated']))\n",
    "    cvscores.append(scores * 100)\n",
    "    print(\"---------------------------\")\n",
    "    print(\"accuracy: %.2f%%\" % (scores*100))\n",
    "    print(\"---------------------------\")\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building baseline model with SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n   Legitmate       0.00      0.00      0.00        30\n      Direct       1.00      0.07      0.13        14\n   Ofuscated       0.81      0.37      0.51        35\n\n   micro avg       0.82      0.18      0.29        79\n   macro avg       0.60      0.15      0.21        79\nweighted avg       0.54      0.18      0.25        79\n samples avg       0.18      0.18      0.18        79\n\n---------------------------\naccuracy: 17.72%\n---------------------------\n              precision    recall  f1-score   support\n\n   Legitmate       0.00      0.00      0.00        23\n      Direct       1.00      0.05      0.10        20\n   Ofuscated       0.36      0.11      0.17        36\n\n   micro avg       0.42      0.06      0.11        79\n   macro avg       0.45      0.05      0.09        79\nweighted avg       0.42      0.06      0.10        79\n samples avg       0.06      0.06      0.06        79\n\n---------------------------\naccuracy: 5.06%\n---------------------------\n              precision    recall  f1-score   support\n\n   Legitmate       0.20      0.05      0.08        21\n      Direct       0.00      0.00      0.00        18\n   Ofuscated       0.71      0.25      0.37        40\n\n   micro avg       0.58      0.14      0.22        79\n   macro avg       0.30      0.10      0.15        79\nweighted avg       0.41      0.14      0.21        79\n samples avg       0.14      0.14      0.14        79\n\n---------------------------\naccuracy: 13.92%\n---------------------------\n              precision    recall  f1-score   support\n\n   Legitmate       0.00      0.00      0.00        26\n      Direct       1.00      0.05      0.09        22\n   Ofuscated       0.88      0.45      0.60        31\n\n   micro avg       0.88      0.19      0.31        79\n   macro avg       0.62      0.17      0.23        79\nweighted avg       0.62      0.19      0.26        79\n samples avg       0.19      0.19      0.19        79\n\n---------------------------\naccuracy: 18.99%\n---------------------------\n              precision    recall  f1-score   support\n\n   Legitmate       0.00      0.00      0.00        30\n      Direct       1.00      0.08      0.14        13\n   Ofuscated       0.82      0.40      0.54        35\n\n   micro avg       0.83      0.19      0.31        78\n   macro avg       0.61      0.16      0.23        78\nweighted avg       0.54      0.19      0.27        78\n samples avg       0.19      0.19      0.19        78\n\n---------------------------\naccuracy: 19.23%\n---------------------------\n14.99% (+/- 5.31%)\n"
    }
   ],
   "source": [
    "cvscores = []\n",
    "for train, test in kfold.split(X, y):\n",
    "    svc_model = OneVsRestClassifier(SVC(kernel = 'linear')).fit(X[train], y[train]) \n",
    "    scores = svc_model.score(X[test], y[test])\n",
    "    y_pred = svc_model.predict(X[test])\n",
    "    print(classification_report(y[test], y_pred, target_names=['Legitmate', 'Direct', 'Ofuscated']))\n",
    "    cvscores.append(scores * 100)\n",
    "    print(\"---------------------------\")\n",
    "    print(\"accuracy: %.2f%%\" % (scores*100))\n",
    "    print(\"---------------------------\")\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}